---
recall: header
---

### Was ist ein sequentieller Kontrollfluss?

ein Ablaufschema für Programmcode bei dem jeder Befehl nach dem vorherigen ausgeführt wird

### Was ist Parallel Computing?

eine Berechnungstechnik bei der Probleme auf mehrere Recheneinheiten aufgeteilt werden

### Wozu wird Parallel Computing verwendet?

- um Probleme mit einem Computer schneller zu lösen als es mit einem sequentiellen Programm möglich
  wäre
- um größere Probleme in gleicher Zeit zu lösen
- Energie sparen (geringere Taktung aber mehr Prozessoren => weniger Energie)

### Wofür steht die Abkürzung *FLOPS*?

floating-point operations per second

### Was sind Beispiele für große Probleme, die mittels Parallel Computing gelöst werden?

- Wettersimulationen
- Proteinfaltung (mehr oder weniger abgelöst durch KI AlphaFold von Google Deepmind)
- computergenerierte Szenen (auf GPUs)
- Big Data Analyse

### Welche Prozessorfunktion sorgt für eine Abweichung vom sequentiellen Kontrollfluss auf Hardware-Ebenen?

Superskalarität

### Was ist Superskalarität?

die Fähigkeit eines einzelnen Prozessors mit mehreren Verarbeitungseinheiten zwei unabhängige
Befehle eines Programms gleichzeitig auszuführen

### Was ist *automatische Parallelisierung*?

Umwandlung eines sequentiellen Programmcodes in ein parallel ausgeführtes durch einen geeigneten
Compiler

### Wofür steht die Abkürzung PBLAS?

parallel basic linear algebra subprograms

### Was ist der einfachste Weg für ein Programmiery ein Programm zu parallelisieren?

Nutzung von Framworks mit parallelisierten Algorithmus um Teilaufgaben eines Programms parallel
ablaufen zu lassen

### Was ist *Dennard-Scaling*?

ein Skalierungsgesetz, das besagt, dass bei schrumpfenden Transistoren und steigender Taktrate die
Energiedichte auf dem Chip konstant bleibt

### Warum werden statt kleinerer Transistoren und höherer Taktraten eher mehr Prozessorkerne auf Chips untergebracht?

Grenzen des Dennard-Scaling erreicht, weitere Erhöhung der Taktraten würde zu nicht abführbarer
Wärme führen und damit die Rechenleistung nicht mehr erhöhen

### Wozu führt der Fokus auf mehr Prozessorkerne in der Softwareentwicklung?

Programme müssen parallelisiert werden, um Leistung eines Chips auszunutzen, da mehr Prozessorkerne
als im Betriebssystem rechenbereite Programme zur Verfügung stehen

### Welche Größe wird für die Bewertung der Paralleliserung von Programmen genutzt?

die Laufzeit (gegenüber sequentieller Ausführung)

### Was ist der *absolute Speedup* durch Parallelisierung?

Quotient aus Laufzeit für sequentielle Ausführung (nicht-paralleles Programm) geteilt durch Laufzeit
bei paralleler Ausführung

### Was ist der *relative Speedup* durch Parallelisierung?

Quotient aus Laufzeit des parallelen Programms auf einem Prozessorkern geteilt durch Laufzeit bei
paralleler Ausführung mit $p$ Kernen

### Wie stehen absoluter Speedup und relativer Speedup zueinader?

absoluter Speedup ist kleiner als relativer Speedup

### Warum ist der absoluter Speedup für gewöhnlich kleiner als relativer Speedup?

Parallelisierung eines Programms sorgt für Overhead in der Programmierung, sodass ein sequentielles
Programm für gewöhnlich weniger Laufzeit benötigt als ein paralleles Programm, das nur auf einem
Prozessorkern ausgeführt wird

### Was ist der *Break-Even-Point* der Parallelisierung?

die minimale Anzahl Prozessorkerne bei der die Ausführung des parallelen Programms schneller ist als
die des sequentiellen

### Was sind Faktoren, die für Mehraufwand bei der Parallelierung eines Programms führen?

Koordination der Kerne und Datenverteilung

### Was ist *superlinearer Speedup*?

wenn der Speedup größer ist als die Anzahl der verwendeten Prozessorkerne

### Wie entsteht superlinearer Speedup?

bei Verwendung von mehr Kernen, wird auch mehr Cache verwendet und damit die Cache-Hit-Rate erhöht,
was zu einer Verringerung der Laufzeit mit einem Faktor $S(p)$ führt, der größer als die Anzahl der
verwendeten Kerne $p$ ist.

### Was besagt *Amdahl's Law*?

teilt sich eine Berechnung in einen sequentiellen Anteil (Initialisierung / Koordination) und einen
perfekt parallelisierbaren Teil, so ist der Maximalwert des des absoluten Speedup der Kehrwert des
Anteils sequentieller Berechnungen (Faktor $f$ in $(0, 1]$)

### Welche Gleichungen liegen *Amdahl's Law* zugrunde?

$$ \begin{align*} t(p) &= f \cdot t_s + \frac{(1-f) \cdot t_s}{p} \\
S(p) &= \frac{t(1)}{t(p)} = \frac{f \cdot t_s + (1-f) \cdot t_s}{f \cdot t_s + \frac{(1-f) \cdot
t_s}{p}} = \frac{f + (1-f)}{f + \frac{1-f}{p}} = \frac{1}{f + \frac{1-f}{p}} \end{align*} $$  
mit 
- $f$: Anteil der sequentieller Berechnungen
- $p$: Anzahl Prozessorkerne
- $t_s$: Laufzeit bei rein sequentieller Berechnung

### Was ist *Gustafson's Law*?

TODO eine Überarbeitung von Amdahl's Law unter der Annahme, dass Probleme mit stärkerer
Parallelisierung wachsen, aber der sequentielle Anzahl konstant bleibt, also gegenüber dem
parallelisierbaren Teil verschwindet. Amdahl's Law betrachtet eine Verringerung der Laufzeit des
parallelisierbaren Teils einer Berechnung, Gustafson hingegen eine Erhöhung der Laufzeit eines
sequentiell berechneten Parallel-Anteils eines Programms.

### Was besagt *Gustafson's Law*?

Bei adäquater Vergrößerung des Problems bei S teigerung der Parallelisierung teilt sich eine
Berechnung in einen sequentiellen Anteil (Initialisierung / Koordination) und einen perfekt
parallelisierbaren Teil, so ist der Maximalwert des des absoluten Speedup der Kehrwert des Anteils
sequentieller Berechnungen (Faktor $f$ in $(0, 1]$)

### Welche Gleichungen liegen *Gustafson's Law* zugrunde?

$$ \begin{align*} t(p) &= f \cdot t(p) + (1-f) \cdot t(p) \\
t(1) &= f \cdot t(p) + p \cdot (1-f) \cdot t(p) \\
S(p) &= \frac{t(1)}{t(p)} = \frac{f \cdot t(p) + p \cdot (1-f) \cdot t(p)}{f \cdot t(p) + (1-f)
\cdot t(p)} = \frac{f + p \cdot (1-f)}{f + (1-f)} = f + p \cdot (1-f) \end{align*} $$  
mit 
- $f$: Anteil der sequentieller Berechnungen
- $p$: Anzahl Prozessorkerne

### Was sind *Strong Scaling* und *Weak Scaling*?

Bewertungskriterien für parallelisierte Algorithmen mit Unterschiedlichen annahmen über die
Problemgröße bei steigender Parallelisierung

### Was sind die Kriterien zur Bewertung eines Algorithmus bei *Strong Scaling*?

Die Problemgröße bleibt konstant, aber die Anzahl der genutzten Prozessorkerne steigt. Das
entspricht dem Anzatz von Amdahl.

### Was sind die Kriterien zur Bewertung eines Algorithmus bei *Weak Scaling*?

Die Problemgröße wächst mit steigender Paralleliserung, die strikt sequentielle Arbeit bleibt dabei
absolut konstant. Das entspricht dem Anzatz von Gustafson. Es wird damit $f$ abhängig von $p$.

### Was ist Parallelisierungsoverhead?

Aufwand im Programm, der nur getrieben werden muss, um das Programm auf mehrere Thread / Prozesse zu
verteilen

### Was sind Beispiele für Arbeiten, die zum Parallelisierungsoverhead zählen?

- Erstellen paralleler Regionen
- Laden spezieller Laufzeitbibliotheken
- Synchronisierung von Threads oder Prozessen
- Kommunikation zwischen Threads oder Prozessen

### In welche Zeitanteile lässt sich die Ausführungszeit eines Programms unterteilen?

- $t_{cpu}$: Berechnung mit Daten aus lokalem Speicher eines Prozessors
- $t_{com}$: Austausch von Daten zwischen Prozessoren
- $t_{wait}$: Wartezeit
- $t_{sync}$ Synchronisierung der Prozessoren
- $t_{place}$: Zuweisung von Aufgaben an Prozessoren
- $t_{start}$: Start der Aufgaben auf allen Prozessoren

### Wie setzt sich der Anteil Setup-Zeit der Ausführungszeit eines Programms zusammen?

Zuweisung von Aufgaben an Prozessoren und Start der Aufgaben auf allen Prozessoren  
$t_{place} + t_{start}$

### Wie setzt sich der Overhead zusammen?

$t_{com} + t_{wait} + t_{sync}$

### Wofür steht die Abkürzung *PTP*?

processor time product

### Wie wird das PTP berechnet?

$PTP(p) = t(p) \cdot p$  
mit 
- $t(p)$: Ausführungszeit einer parallelisierten Berechnung
- $p$: Anzahl Prozessorkerne

### Wie berechnet sich die *Work* eines parallelisierten Prozesses?

$PTP(p) - t_{idle}$

### Was ist eine computation-bound Berechnung?

wenn die Zeit für die Berechnung des eigentlichen Problems viel größer ist als der Aufwand für die
Kommunikation zwischen den beteiligten Threads / Prozessen

### Was ist eine communication-bound Berechnung?

wenn die Zeit für die Kommunikation zwischen den beteiligten Threads / Prozessen viel größer ist als
der Aufwand für die Berechnung des eigentlichen Problems 

### Auf wen geht die klassische Einteilung von Rechnerarchitekturen zurück?

Michael J. Flynn

### Welche Kriterien führen zu einer Einteilung einer Architektur in der Flynnsche Klassifikation?

- Anzahl Instruktionsströme
- Anzahl Datenströme

### Welche vier Kategorien gibt es in der Flynnsche Klassifikation?

- SISD: single-instruction single-data (klassischer Single Core)
- SIMD: single-instruction multiple-data (Single Core mit Vektorinstruktionen (AVX/SSE), GPU)
- MIMD: multiple-instruction multiple-data (Supercomputer)
- MISD: multiple-instruction single-data (leer)

### In welche Kategorien von Speicherstrukturen lassen sich Computersysteme einteilen?

- Shared-Memory-System
- Distributed-Memory-System / Message-Passing-System

### Was ist *Virtual Shared Memory* / *Distributed Shared Memory*?

Erweiterung der Kategorie "Distributed-Memory-System" um physikalisch ausgelagerte Speicher, die
über ein Netzwerk angesprochen werden können

### Wofür steht die Abkürzung *NUMA*?

non-uniform memory access

### Wofür steht die Abkürzung *NCC-NUMA*?

non cache coherent non-uniform memory access

### In welche Speicherstruktur-Kategorie werden heutige Systeme mit mehreren CPU-Kernen oder Prozessor-Sockeln eingeordnet?

CC-NUMA (cache coherent non-uniform memory access)

### Was ist *User-Space-Virtual-Shared-Memory*?

so wird es genannt, wenn mit der Shared-Memory Programmiersichtweise auf Message-Passing-Maschinen
gearbeitet wird

### Wofür steht die Abkürzung *HPC*?

High Performance Cluster

### Was ist das Ziel der Verwendung eines HPC?

Verarbeitungszeit (makespan) eines parallelen Programms minimieren

### Wofür steht die Abkürzung *HTC*?

High Throughput Cluster

### Was ist das Ziel der Verwendung eines HTC?

viele unabhängige Programme abarbeiten

### Was ist das Ziel der Verwendung eines High Availability Cluster (HA)?

maximale Verfügbarkeit durch schnelles Umschalten beim Ausfall eines Computers

### Was ist die programmatische Herausforderung bei HPC-Systemen?

Programm derart zu entwickelt, dass es effizient auf einem parallelen Cluster ausgeführt werden kann

### Was ist ein Beowulf Cluster?

Zusammenschalten von mehreren handelsüblichen PCs als günstige Alternative zu maßgeschneiderten HPC
mit Spezialhardware

### Wer hat das Konzept des Beowulf Clusters entwickelt?

Thomas Sterling und Donald Becker (NASA, 1994)

### Wie ist ein Beowulf Cluster aufgebaut?

- Server-Knoten, der als Bedieneinheit dient und die Arbeit an die Client-Knoten verteilt, die als
reine Rechen-Knechte konfiguriert sind und nur i.V.m dem Server-Knoten nutzbar sind
- Datenbeschaffung der Clients über paralleles oder Netwerkdateisystem

### Was ist ein Exascale-System?

ein HPC-Cluster das mindestens $10^{18}$ IEEE754 Double-Precision Operationen pro Sekunde (FLOPS)
berechnen kann

### Wofür steht die Abkürzung *FPGA*?

Field Programmable Gate Array

### TODO Beschreibung "Juwel" HPC wichtig?

### Was ist bei heutigen Supercomputern der Flaschenhals der Performance?

Bandbreite der Kommunikation oder Latenz von Speicher

### Was ist Latenz?

Dauer das erste Byte / Wort von Daten über eine Verbindung zu übertragen

### Was ist der Unterschied zwischen Latenz und Bandbreite?

TODO

### Welche Leistungsgrenzen eines Systems spielen eine Rolle für die Performance?

- FLOPS
- verfügbare Operationen
- Speichebandbreite
- Speicherlatenz
- Befehlswarteschlange (Cache)
- Netzwerk
- Festplatte

### In welche zwei Kategorien können alle Leistungsgrenzen eines Systems eingeordnet werden?

Geschwindigkeit und Datenfluss (speed and feed)

### Wie werden die theoretisch möglichen FLOPS eines Computersystems berechnet?

$F_T = C_v \cdot f_c \cdot I_c$  
mit
- $C_v$: Anzahl virtueller Kerne
- $f_c$: Taktrate
- $I_c$: Instructions per Cycle

### Was ist die *Theoretical Peak Performance* eines Computersystems?

die rechnerisch erreichbare Anzahl von Gleitkommaoperationen pro Sekunden (FLOPS)

### Was ist eine Dual-Sockel-Hauptplatine?

ein Mainboard mit zwei Prozessor-Steckplätzen

### Wofür steht die Abkürzung *MTR*?

Maximum Transfer Rate

### In welcher Einheit wird die Daten- oder Speicherübertragungsrate angegeben?

Millionen von Übertragungen pro Sekunde

### Wie wird die theoretisch mögliche Speicherbandbreite eines Computersystems berechnet?

$B_T = MTR \cdot M_C \cdot T_S \cdot N_S$  
mit 
- $MTR$: Übertragungsrate
- $M_C$: Anzahl Kanäle
- $T_W$: Transferbreite (Bytes pro Übertragung)
- $N_S$: Anzahl Sockel

### Warum ist die erreichbare Speicherbandbreite für gewöhnlich deutlich geringer als die theoretische?

Auswirkungen der übrigen Speicherhierarchie

### Was ist *Speicherlatenz*?

Zeit, die benötigt wird, um das erste Datenbyte einer Speicherstufe zu lesen

### Wie hoch kann die Speicherlatenz für den Hauptspeicher sein?

ca. 400 Taktzyklen

### In welchen Paketgrößen werden Daten aus der nächsten Cache-Ebene nachgeladen?

Cache-Zeile

### Welche vier Varianten für die Messung der Speicherbandbreite bietet *STREAM-Benchmark*?

- Copy: Kopiert ein Array
- Scale: Multipliziert ein Array mit Faktor
- Add: Addiert Offset zu Array
- Triad: Multipliziert ein Array mit Faktor und addiert ein Offset

### Wofür steht die Abkürzung *ERT*?

Empirical Roofline Toolkit

### Wozu dient das Empirical Roofline Toolkit?

Messen von maximaler Performance der CPU und maximaler Speicherbandbreite eines Systems

### Was ist das Besondere am Roofline-Modell?

Es kombiniert Aspekte wie Lokalität, Bandbreite und diverse Parallelisierungsmethoden zu einer
übergreifenden Leistungskennzahl.

### Was ist die Arbeit $W$ einer Anwendung / eines Kernels?

Anzahl der ausgeführten Operationen, meist angegeben in FLOPS, kann aber auch andere Operationen
einbeziehen

### Was ist der Speicherzugriff $Q$ einer Anwendung / eines Kernels?

Anzahl der Bytes, die während der Ausführung vom Speicher übertragen werden (sowohl lesend als auch
schreibend)

### Wovon hängt die Metrik des Speicherzugriff $Q$ einer Anwendung / eines Kernels maßgeblich ab?

Cache-Hierarchie der Plattform

### Wie werden unterschiedliche Cache-Hierarchien in einem Roofline-Diagramm berücksichtigt?

Jede Cache-Ebene hat unterschiedliche maximale Speicherbandbreiten, die im Roofline-Modell
eingetragen werden können. Ist die Datenmenge einer Anwendung klein genug, um im schnellsten Cache
zu verweilen, gilt die L1-Cache-Speicherbandbreite im Diagramm als limitierende Kurve, sonst L2, L3,
usw.

### In welche Bestandteile wird die die Metrik des Speicherzugriff $Q$ aufgeteilt?

- Lesevorgänge $Q_r$
- Schreibvorgänge $Q_w$

### Was ist die Rechenintensität $I$?

Das Verhältnis aus Arbeit $W$ einer Anwendung / eines Kernels und der dazugehörige Speicherzugriff
$Q$, gibt Operationen pro Byte des Speicherzugriffs an

### Was ist ein *Roofline-Diagramm*?

Darstellung der Leistung $P$ in GFLOPS über die Intensität der Operationen in FLOP/Byte auf
logarithmischer Skala

### Wozu dient das *Roofline-Diagramm*?

Visualisierung der Ergebnisse des Roofline-Modells, um zu ermitteln, ob die CPU-Leistung oder die
Speicherbandbreite der limitierende Faktor der Ausführungsgeschwindigkeit eines Programms ist

### Was ist *Profiling*?

Mittels Hilfsprogrammen feststellen, in welchen Programmteilen eine Anwendung wie viel Zeit
verbringt

### Welches Linux-Programm steht zur Messung der Gesamtlaufzeit eines Programms bereit?

`time`

### Welche Zeiten misst der `time`-Befehl?

- real time: Zeit zwischen Laden und beenden des Programms
- user time: Zeit, die das Programm die CPU beschäftigt hat
- system time: Zeit, die das System im Auftrag des Programms (Systemcalls) gearbeitet hat

### Was sind in der Messung unerwünschte Bestandteile, die `time` erfasst?

- Laden des Programms
- Laden der Laufzeitbibliotheken
- Initialisieren der Daten
- Zuweisung von Speicherplatz
- Test auf Korrektheit
- Ausgabe des Ergebnisses
