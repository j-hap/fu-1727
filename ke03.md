---
recall: header
---

### Wofür steht *OpenMP*?

Open Multi Processing

### Was ist *OpenMP*?

eine Bibliothek zur Parallelisierung von Programmen mittels Thread-Parallisierung

### Welche Speichertechnik kommt bei der Verwendung von OpenMP zum Einsatz?

shared memory (gemeinsamer Speicher)

### Welchen Vorteil bietet die Verwendung von OpenMP bei der Parallelisierung bestehender Software?

Code kann inkrementell parallelisiert werden (eine Schleife nach der anderen zum Beispiel)

### Aus welchen Bestandteilen ist OpenMP aufgebaut?

- Compiler-Direktiven (Pragmas)
- Bibliotheksroutinen
- Umgebungsvariablen

### Welche Programmiersprachen lassen sich mit OpenMP parallelisieren?

- C
- C++
- FORTRAN

### Welche zwei Arten von Variablen werden innerhalb eines OpenMP-Blocks unterschieden?

- private Variablen
- geteilte Variablen

### Wozu dienen die Compiler-Direktiven in OpenMP?

bieten verschiedene Konstrukte, um Programmabschnitte zu parallelisieren und zwischen privaten und
geteilten Variablen zu unterscheidens

### Wozu dienen die Bibliotheksroutinen in OpenMP?

- Abfrage von Informationen zur Laufzeit
- Steuerung der Laufzeitumgebung

### Wozu dienen die Umgebungsvariablen in OpenMP?

Steuerung der Laufzeitumgebung

### Aus welcher Entwicklung entstand die Idee für OpenMP?

- erste Symmetric Multi Core Processors (SMP) in den 1980ern auf dem Markt
- Prozessorspezifische Direktiven zur Verteilung der Arbeit
- Vereinheitlichung der Direktiven über Hardwarehersteller hinweg

### Welche Eigenschaften unterscheiden Threads von Prozessen?

- Threads sind Teil eines Prozesses
- Threads haben alle den gleichen Adressraum
- Threads benötigen weniger Ressourcen als Prozesse, lediglich einen Program Counter und Speicher
  für private Variablen, einen Stack und Register

### Was ist ein Deadlock?

wenn zwei Threads / Prozesse jeweils nur weiter arbeiten können, wenn der jeweils andere weiter
arbeitet, sie also gegenseitig aufeinander warten und deswegen nichts mehr geht

### Was ist das *Fork-Join-Programmiermodell*?

ein Programmiermodell für Parallelismus bei dem ein initialer Thread zur Paralleliserung eines
Abschnitts eine Gruppe von Threads erstellt und selbst zum Master Thread (fork), nach Abschluss der
Arbeiten werden alle Threads bis auf den Master zerstört (join)

### Welcher Header muss eingebunden werden, um OpenMP-API-Aufrufe in C/C++ Code verwenden zu können?

`omp.h`

### Welche OpenMP-API-Funktion liefert die Anzahl Thread in einem parallelen Block?

`omp_get_num_threads()`

### Welche OpenMP-API-Funktion liefert die Nummer des ausführenden Threads in einem parallelen Block?

`omp_get_thread_num()`

### Mit welcher Direktive wird eine parallele Region für OpenMP begonnen?

`#pragma imp parallel`

### Welche Compiler-Flag wird zum Kompilieren von OpenMP-Programmen benötigt?

compilerabhängig, `-fopenmp` für clang / gcc

### Was passiert mit den `#pragma omp` Direktiven, wenn ein Programm ohne OpenMP-Flag kompiliert wird?

sie werden ignoriert und das Programm läuft seriell

### Mit welchem Makro kann man prüfen, ob OpenMP aktiv ist?

`#ifdef _OPENMP`

### Wie sind alle OpenMP Direktiven aufgebaut?

`#pragma omp directive-name [clause[[,] clause]. . . ]`

### Was ist eine *Klausel* in einer OpenMP-Direktive?

mit Komma getrennte, hinter dem Direktiven-Namen stehende Ausdrücke, die das Verhalten des
parallelen Abschnitts beinflussen

### Wozu dient die OpenMP-Direktive `for`?

gleichmäßige Aufteilung der Arbeit einer `for`-Schleife auf alle Threads

### Welche Arten von for-Schleifen lassen sich mit der OpenMP `for`-Direktive parallelisieren?

nur solche mit klassischem Aufbau und ganzzahligen Zählern: `for (var = start; var op end;
inkrement)`

### Welche Randbedingungen an die Schleifenvariablen werden gefordert, um diese mit der OpenMP `for`-Direktive zu parallelisieren?

- Datentyp `(u)int` / `(u)long` / `(u)long long`
- Counter nicht im Schleifen-Body ändern
- Anzahl der Schleifendurchläufe vorher bekannt
- Vergleichsoperator in Abbruchbedingung nur aus `<, <=, >=, >`
- Inkrement immer gleich und nur additiv / subtraktiv

### Warum ist die Form der mit OpenMP-`for` parallelisierbaren Schleifen beschränkt?

um schon zur Compile-Zeit zu bestimmen wie viele Schleifendurchläufe stattfinden werden, um so die
Arbeit aufzuteilen

### Mit welcher OpenMP-Direktive können unterschiedliche Arbeiten auf Threads aufgeteilt werden?

`sections` + `section`

### In welcher Reihenfolge werden bei OpenMP `sections` ausgeführt, wenn nur ein Thread verfügbar ist?

nicht definiert, es kann durchaus die zweite `section` vor der ersten ausgeführt werden

### Wie lässt sich in OpenMP forcieren, dass innerhalb einer parallelen Region eine Anweisung nur einmal ausgeführt wird?

mit der `#pragma omp single` Direktive

### Welcher Thread führt bei `#pragma omp single` die Anweisung aus?

nicht definiert, könnte jeder Thread aus dem Pool sein

### Welcher Thread führt bei `#pragma omp master` die Anweisung aus?

der Thread mit der ID 0

### Wie unterscheidet sich das verhalten der anderen Thread zwischen `#pragma omp single` und `#pragma omp master`?

bei `#pragma omp master` warten die anderen Threads nicht bis der Master Thread die Anweisung
ausgeführt hat, bei `#pragma omp single` hingegen schon

### Was ist eine implizite Barriere in OpenMP?

eine nicht explizit genannte Schranke, an der die Thread mit der Ausführung pausieren, bis alle
Threads die vorherigen Anweisungen abgearbeitet haben, die wird durch einige Direktiven bedingt

### Was ist eine *Race-Condition* (Wettlaufsituation)?

eine Race-Condition tritt auf wenn die Ausführungsreihenfolge von Anweisungen in mehreren Threads
über das Ergebnis des Programms entscheiden

### Was ist ein *Data-Race*?

eine besondere Form der Race-Condition, bei der Lese- und Speicherzugriffe von Threads bei
ungünstiger Reihenfolge zu einem falschen Ergebnis führen

### Welche zwei Arten von Variablen werden in OpenMP unterschieden?

geteilte (shared) und private (private) Variablen

### Was zeichnet *geteilte* Variablen in OpenMP aus?

alle Threads haben gleichzeitig Zugriff darauf

### Was zeichnet *private* Variablen in OpenMP aus?

Jeder Thread hat eine eigene Kopie einer privaten Variablen und kann auch nicht auf die privaten
Variablen anderer Threads zugreifen. Private Variablen sind nur innerhalb einer parallelen Region
gültig.

### Welche Variablen sind in OpenMP standardmäßig zwischen den Threads geteilt?

- statische Variablen
- dynamisch allokierte Objekte
- Variablen im Heap-Speicher
- innerhalb eines parallelen Bereichs verwendete Variablen, die außerhalb deklariert wurden

### Welche Variablen sind in OpenMP standardmäßig für einen Thread privat?

- innerhalb eines parallelen Bereichs deklarierte Variablen
- Schleifenvariablen in parallelisierten Schleifen
- innerhalb eines parallelen Bereichs mit allocate zugewiesene Variablen

### Wozu dient die `shared`-Klausel in einer OpenMP-Direktive?

explizite Deklaration von in einer parallelen Region gemeinsam genutzten Variablen

### Was ist bei Verwendung von geteilten Variablen in OpenMP bezüglich der Sichtbarkeit von Änderungen in anderen Threads zu beachten?

ändert ein Thread eine Variable, kann die Änderung verzögert an die anderen Threads propagiert
werden, das hängt davon ab, wie die Plattform Cache Kohärenz herstellt

### Was ist das *relaxed-consistency*-Modell von OpenMP?

der OpenMP-Standard erlaubt es, dass Threads die Werte von geteilten Variablen in einem
Thread-privaten Cache halten und ändern und die Änderungen erst an bestimmten
Synchronisierungspunkten für alle Threads sichtbar werden

### Wozu dient die `private`-Klausel in einer OpenMP-Direktive?

explizite Deklaration von in einer parallelen von jedem Thread privat genutzten Variablen

### Welchen Einfluss hat die Markierung einer Variablen mittels `private`-Klausel in der OpenMP-Direktive auf ihren Wert?

sie sind beim Eintritt und beim Verlassen des parallelen Konstrukts undefiniert, muss also, auch
wenn sie vorher einen Wert hatte, im parallelen Konstrukt belegt werden, bevor sie verwendet wird

### Wozu dient die `lastprivate`-Klausel in einer OpenMP-Direktive?

die markierte private Variable wird nach dem parallelen Konstrukt nicht undefiniert, sondern behält
den Wert bei, den sie zuletzt im parallelen Konstrukts gehalten hat, entweder der letzten Iteration
einer Schleife oder der letzten Section eines Sections-Bereich

### Wozu dient die `firstprivate`-Klausel in einer OpenMP-Direktive?

die markierte private Variable ist beim Eintritt in das parallele Konstrukt nicht undefiniert,
sondern wird für jeden Thread mit ihrem letzten Wert vorbelegt

### Wozu dient die `default`-Klausel in einer OpenMP-Direktive?

Festlegen vom default-Verhalten von nicht mit `private` oder `shared` markierten Variablen  
- `default(shared)`: alle nicht markierten Variablen sind geteilt zwischen den Threads
- `default(none)`: alle im parallelen Konstrukt verwendeten Variablen müssen explizit markiert
  werden
- `default(private)`: alle nicht markierten Variablen sind privat für jeden Thread (nicht
  unterstützt in C/C++)

### Wozu dient die `reduce`-Klausel in einer OpenMP-Direktive?

legt fest wie Zuweisung auf eine geteilte Variable durch mehrere Threads zu einem Endergebnis
kombiniert werden

### Welche Anforderungen werden an eine `reduce`-Operation in OpenMP gestellt?

muss assoziativ und kommutativ sein

### Wie verhält sich die `reduce`-Operation in OpenMP wenn die geteilte Variable vorbelegt ist?

Die Vorbelegung wird nicht überschrieben, sondern geht mit in das Ergebnis ein. Ist die
`reduce`-Operation das `+`, so ergibt eine Vorbelegung der geteilten Variablen ein Offset in der
resultierenden Summe

### Wie ist die Reihenfolge der Abarbeitung der Threads in einer `reduce`-Operation in OpenMP definiert?

gar nicht, weshalb hier insbesondere bei Gleitkommazahlen unterschiedliche Ergebnisse auftreten
können, abhängig davon ob erst große oder erst kleine Zahlen verarbeitet werden

### Welche Operatoren werden in einer `reduce`-Operation in OpenMP unterstützt?

- `+` (Addition)
- `*` (Multiplikation)
- `-` (Subtraktion)
- `&` (bitwise AND)
- `|` (bitwise OR)
- `^` (bitwise XOR)
- `&&` (logisches UND)
- `||` (logisches ODER)
- `min` (Minimum)
- `max` (Maximum)

### Wozu dient die Synchronisation in OpenMP?

- Sicherstellen der Reihenfolge der Aktualisierung einer `shared` Variable
- Sicherstellen des exklusiven Schreibzugriffs auf eine `shared` Variable

### Welche Direktiven gibt es für die Synchronisation von Threads in OpenMP?

- `barrier`
- `critical`
- `atomic`
- `taskwait` (nicht im Kurstext behandelt)
- `flush` (nicht im Kurstext behandelt)
- `ordered` (nicht im Kurstext behandelt)
- `depend` (nicht im Kurstext behandelt)

### Wozu dient die `#pragma omp barrier` Direktive?

Schafft eine Barriere im Programm an der alle Threads warten, bis alle Threads die Barriere erreicht
haben um dann weiter zu rechnen.

### Welche Regeln müssen beim Einfügen einer explizieren Barriere in OpenMP berücksichtigt werden?

Um Deadlocks zu vermeiden müssen
- all Barrieren von allen Threads oder von keinem erreicht werden
- alle Threads alle Barrieren in der gleichen Reihenfolge erreichen  
  
in C/C++ muss außerdem die Deklarative entwernt werden können, ohne ein syntaktisch falsches
Programm zurückzulassen.

### Wozu dient die `#pragma omp critical` Direktive in OpenMP?

definiert einen Bereich eines parallelen Konstrukts, in dem sich stets nur ein Thread befinden darf,
also andere Threads ihre Ausführung unterbrechen, bis der aktuell im Abschnitt rechnende Thread
diesen Abschnitt verlassen hat

### Wozu dient die `#pragma omp atomic` Direktive in OpenMP?

Ähnlich wie `#pragma omp critical` sorgt es für die exklusive Ausführung eines Programmteils. Mit
`atomic` kann allerdings immer nur eine einzige Zuweisungsanweisung markiert werden.

### Was ist der Unterschied zwischen den `critical` und `atomic` Direktiven in OpenMP?

`critical` kann für einen ganzen Codeabschnitt mit beliebigen Anweisungen verwendet werden, `atomic`
immer nur für eine einzige Zuweisungsanweisung, die auf der rechten Seite des `=` eine simple
Binäroperation ausführt

### Welche Binäroperationen werden in `atomic`-Direktiven in OpenMP unterstützt?

die nicht-überladenen Varianten von
- `+` (Addition)
- `*` (Multiplikation)
- `-` (Subtraktion)
- `/` (Division)
- `&` (bitwise AND)
- `|` (bitwise OR)
- `^` (bitwise XOR)
- `<<` (left shift)
- `>>` (right shift)

### Welchen Vorteil hat die `atomic`-Direktive gegenüber der `critical` in OpenMP?

Der exklusive Zugriff auf die Zuweisung wird mittels Hardwareunterstützung realisiert und ist daher
meist schneller.

### Warum kann es sinnvoll sein die Anzahl der von OpenMP verwendeten Threads gegenüber der vom Betriebsystem ausgewiesenen Anzahl zu verändern?

- Hyperthreading, also die Abarbeitung von mehreren Threads auf dem gleichen physischen Kern, ist
  für OpenMP-Anwendungen häufig nicht sinnvoll
- zu großer Overhead bei starker Parallelisierung, der zum Flaschenhals wird
- Belastung des Programms durch andere, parallel arbeitende Nutzer / Prozesse, die OpenMP-Threads
  unterbrechen und ausbremsen
- Überbrücken von IO-Wartezeiten durch mehr Threads als es Kerne gibt

### Welche Möglichkeiten gibt es die Anzahl der von OpenMP verwendeten Threads festzulegen?

1. Umgebungsvariable `OMP_NUM_THREADS` (niedrigste Priorität)
2. Funktion `omp_set_num_threads`
3. Direktive `#pragma omp num_thread` (höchste Priorität)

### Wozu dient *Scheduling* in OpenMP?

Festlegen der Zuordnung von Iterationen einer Schleife zu Threads

### Welche *Scheduling-Strategien* unterstützt OpenMP?

- static
- dynamic
- guided
- auto
- runtime

### Welche Möglichkeiten gibt es die Scheduling-methode in OpenMP festzulegen?

1. Umgebungsvariable `OMP_SCHEDULE` (niedrigste Priorität)
2. Funktion `omp_set_schedule`
3. Klausel `schedule` (höchste Priorität)

### Was zeichnet die `static` Scheduling-Strategie in OpenMP aus?

zu Beginn der Iteration (statisch) werden die Iterationen in Chunks zerlegt und reihum an die
Threads verteilt

### Was zeichnet die `dynamic` Scheduling-Strategie in OpenMP aus?

jedem Thread with ein Chunk an Iterationen zugewiesen und wenn der Thread damit fertig ist, holt er
sich den nächsten Chunk ab, so wird die Rechenlast gleichmäßiger auf die Threads verteilt

### Was zeichnet die `guided` Scheduling-Strategie in OpenMP aus?

wie `dynamic`, allerdings wird die Größe der zugewiesenen Chunks zum Ende der Schleife hin kleiner

### Was zeichnet die `auto` Scheduling-Strategie in OpenMP aus?

die Entscheidung über das Scheduling wird an den Compiler delegiert

### Was zeichnet die `runtime` Scheduling-Strategie in OpenMP aus?

die Entscheidung über das Scheduling wird an die Laufzeitumgebung delegiert, die entweder den Wert
aus `omp_get_schedule`, der Umgebungsvariable `OMP_SCHEDULE` oder dem default der Implementierung
verwendet

### Was ist die default-Chunk-Größe beim OpenMP Schedulung?

- `static`: Anzahl der Iterationen ingesamt wird durch die Anzahl der Threads geteilt und so jeweils
  ein Chunk jedem Thread zugeordnet
- `dynamic`: Default ist 1
- `guided`: Default ist 1, beschreibt aber nur die minimale Größe des Chunks, zu Beginn der
  Iteration sind die Chunks größer

### Wozu dient die `nowait`-Direktive in OpenMP?

normalerweise wird an einer parallelisierten Schleife am Ende eine Barriere eingeführt, sodass auf
alle Threads gewartet wird, bevor weiter berechnet wird. Mit der nowait Anweisung kann diese
Barriere entfernt werden. Dies ist nützlich wenn zwei unabhängige Schleifen hintereinander berechnet
werden sollen. Dann können die Threads der ersten Schleife direkt mit der Abarbeitung der zweiten
Schleife beginnen, obwohl noch Threads mit der Bearbeitung der ersten Schleife beschäftigt sind.
