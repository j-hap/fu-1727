---
recall: header
---

### Was definiert *Big Data*?

die fünf Vs

### Was sind die 5 Vs von *Big Data*?

- volume (Volumen)
- velocity (Geschwindigkeit)
- variety (Vielfältigkeit)
- veracity (Wahrhaftigkeit)
- value (Wert)

### Wofür steht *volume* in den 5 Vs von Big Data?

die zu verarbeitende Datenmenge übersteigt die Speicher- und Verarbeitungsanforderungen ($\geq$
Terabyte $(10^{12})$)

### Wofür steht *velocity* in den 5 Vs von Big Data?

Daten werden mit hoher Geschwindigkeit erzeugt, hohe Geschwindigkeit sorgt für große Mengen
aktueller Daten und damit auch deren Bedeutung

### Wofür steht *variety* in den 5 Vs von Big Data?

(Vielfältigkeit)
- viele Quellen
- viele Formate
- viele Strukturen (strukturiert / halbstrukturiert / unstrukturiert)

### Was zeichnet strukturierte Daten aus?

sie können tabellenartig in Datenbanken dargestellt werden

### Was zeichnet semistrukturierte Daten aus?

nicht tabellarisch darstellbar, aber noch geordnet durch z.B. Hierarchie, wie XML, JSON

### Was zeichnet unstrukturierte Daten aus?

unorganisierte Daten wie Fließtext, Bilder, Audiodateien

### Wofür steht *veracity* (over auch *validity*) in den 5 Vs von Big Data?

(Wahrhaftigkeit) Daten müssen auf ihren Wert bezüglich
- Vertrauenswürdigkeit
- Genauigkeit
- Authentizität
  
hin untersucht werden, weil ihre Eigenschaften in diesen Kategorien stark schwanken können

### Wofür steht *value* in den 5 Vs von Big Data?

(Wert) Wert der Daten für eine Analyse, für gewöhnlich müssen es aktuelle Daten sein, die auch zum
Analyseziel passen (unternehmerischer Mehrwert)

### Wie unterscheiden sich Frameworks für Big Data und HPC Berechnungen?

HPC-Frameworks sind auf schnelle und effiziente Berechnungen ausgelegt. Big Data Anwendungen sind
wesentlich facettenreicher, weshalb die Frameworks viel komplexer sind

### Wie unterscheiden sich die Anforderungen bezüglich Fehlertoleranz und Ausfallsicherheit zwischen Big Data und HPC Systemen?

Fehler auf einem Knoten eines HPC-Systems führt zum Abbruch der Berechnung, bei Big-Data Systemen
darf das nicht passieren, hier sind die verarbeiteten Daten wesentlich Fehleranfälliger, was durch
das System abgefedert werden muss

### Welche zwei Arten von Systemen werden in der Literatur unterschieden?

- transaktionale Systeme (OLTP)
- analytische Systeme (OLAP)

### Was zeichnet *transaktionale* Systeme aus?

Systeme, die Transaktionsverarbeitung unterstützen, also kleinschrittige Verarbeitung, bei der die
ACID-Eigenschaft eine wichtige Rolle spielt. Es wird in jeder Transaktion ein eindeutig
identifizierbarer Datenschnipsel verarbeitet

### Was ist die ACID-Eigenschaft von Systemen?

ACID steht für
- atomicity
- consistency
- isolation
- durability
  
und beschreibt die Vorraussetzungen für die Verlässlichkeit eines (Datenbank)Systems

### Was zeichnet *analytische* Systeme aus?

kein Fokus auf ACID-Eigenschaften, Verarbeitung von unterschiedlichen Datentypen, ggf. mit
Duplikaten oder auch fehlerhaften Daten um Trends / Prognosen herauszuarbeiten

### In welche Kategorie von Systemen fallen Big Data Systeme?

analytische Systeme

### Was ist das CAP-Theorem?

ein von Eric Brewer vorgeschlagenes Theorem, das besagt, dass ein verteiltes System stets nur zwei
der drei Eigenschaften 
- Consistency
- Availability
- Partition Tolerance
  
sicherstellen kann. Da nur ein verteiltes System partitioniert werden kann, gibt es nur hier die
Eigenschaft Partitionstoleranz. Bei verteilten Systemen muss man sich also entscheiden, ob man im
Falle eines Netzwerkausfalls entweder die Konsistenz oder die Verfügbarkeit aufrecht erhalten will

### Wofür steht die Abkürzung CAP im CAP-Theorem?

- Consistency
- Availability
- Partition Tolerance

### Was ist das BASE-Prinzip eines Systems?

steht für: **B**asically **A**vailable, **S**oft state, **E**ventual consistency
  
solche Systeme priorisieren Verfügbarkeit über Konsistens und synchronisieren nur in gewissen
Zeitabständen

### Wie unterscheiden sich die Festspeichersysteme von Big Data und HPC Systemen?

- HPC: Storage Knoten, die den Rechnenknoten Daten liefern, spezielles Datennetzwerk (geringe
  Latenz)
- Big Data: Rechenknoten speichern ihre Daten selbst, um größtmögliche Verfügbarkeit zu haben, kein
  spezielles Datennetzwerk, da Latenz nicht so wichtig

### Was ist *MapReduce*?

ein Programmiermodell von Google und die dazugehörige Implementierung zur Verarbeitung und Erzeugung
großer Datensätze

### Welche zwei Funktionen müssen bei MapReduce zur Verarbeitung von Daten definiert werden?

- Map: Beschreibt wie aus einer Eingabe eine ggf. mehrteilige Ausgabe erstellt wird
- Reduce: beschreibt wie aus der Ausgabe der Map-Funktion das Gesamtergebnis bestimmt wird

### In welche Phasen teilt sich ein MapReduce Programm auf?

1. Map
2. Shuffle
3. Reduce
   
### Was geschieht in der Shuffle Phase eines MapReduce Programms?

Ergebnisse der Map-Phase werden gemäß ihrer Schlüssel gruppiert

### Was ist *Hadoop*?

eine Open Source Framework für Big Data Systeme der Apache Foundation um das MapReduce
Programmiermodell TODO

### Aus welchen Komponenten besteht Hadoop v1?

- Hadoop Distributed File System: Dateisystem für verteilten Festplattenspeicher
- MapReduce: Standardprogrammiermodell und Resourcenmanagement
- Hive: Erweiterung von MapReduce zur Verwendung von HiveQL, einer SQL ähnlichen Skriptsprache um
  Anfragen an Hadoop zu stellen (statt ein Programm zu schreiben)
- Pig: Erweiterung von MapReduce zur Verwendung von Pig Latin, einer Skriptsprach zur einfachen
  Formulierung von Anfragen an Hadoop (auch mit unstrukturierten Daten)
- Mahout: Machine Learning Bibliothek zur Verwendung mit MapReduce 
- HBase: einfaches Datenbanksystem zur Verwaltung von sich selten ändernden Daten auf dem
  Hadoop-Cluster
- Oozie: Workflow Management und Job-Scheduling
- ZooKeeper: Verwaltung von Konfigurationen und Synchronisation von Clustern
- Ambari: Überwachung und Management von Clustern

### Wofür steht die Abkürzung *HDFS*?

Hadoop Distributed File System

### Welche zwei Arten von Knoten gibt es im *Hadoop Distributed File System*?

- NameNode
- DataNode(s)

### Wie groß ist standardmäßig ein Block in HDFS?

128MB

### Wie oft wird ein Block standardmäßig in HDFS repliziert?

dreimal

### Wie viele NameNodes hat das HDFS eines Hadoop Clusters?

einen 

### Was ist eine Hearbeat-Nachricht im HDFS?

eine alle 3 Sekunden wiederholte Nachricht von DataNodes and den NameNode, die aussagt, dass der
DataNode verfügbar ist

### Welche Informationen enthält eine Hearbeat-Nachricht im HDFS?

- Gesamtspeicherkapazität
- Prozentsatz des belegten Speichers
- Anzahl gleichzeitiger Verbindungen

### Was passiert, wenn ein DataNode im HDFS keine Heartbeat-Nachricht sendet?

die ausgefallenen Kopien von Datenblöcken werden auf den anderen DataNodes repliziert

### Wie läuft ein Lesevorgang im HDFS ab?

1. Client sendet Nachricht an NameNode, um Speicherort des gewünschten Datenblocks zu erfahren
2. NameNode sendet Liste aller DataNodes, die Kopien des Blocks halten
3. Client wählt nächstgelegene Kopie aus und fragt dort Daten an

### Wie läuft ein Schreibvorgang im HDFS ab?

1. Client sendet Nachricht an Namenode, um Schreiborte zu erfahren
2. NameNode sendet Liste über alle vorhandenen Kopien
3. Client schickt nächstem DataNode zu schreibende Daten
4. erster DataNode schreibt Daten und leitet Anfrage an zweiten DataNode weiter
5. zweiter DataNode schreibt Daten und leitet Anfrage an dritten DataNode weiter
6. dritter DataNode schreibt Daten
7. dritter DataNode bestätigt Schreibvorgang an zweiten DataNode
8. zweiter DataNode bestätigt Schreibvorgang an ersten DataNode
9. erster DataNode bestätigt Schreibvorgang an Client
10. Client bestätigt Schreibvorgang an NameNode

### Welche Maßnahmen gibt es die Fehlertoleranz eines HDFS zu erhöhen?

- sekundärer Namensknoten: liest regelmäßig die Systemprotokolle des primären NameNode, um eine
  Sicherung der MetaDaten zu erstellen und die Funktion des NameNodes zu übernehmen, wenn dieser
  ausfällt
- Avatar-NameNode: Avatar-NameNode ist ein Wrapper um ein Paar von NameNodes, wobei einer der beiden
  eine Redundanz des ersten ist und einspringt, wenn der erste versagt

### Wie werden die Einzelaufträge eines MapReduce Jobs genannt?

Tasks

### In welche Arten von Knoten teilt sich ein MapReduce-Cluster auf?

- Job-Tracker
- Task-Tracker

### Welche Aufgabe hat der Job-Tracker einem MapReduce-Cluster?

Masterknoten für den Job und weist den Task-Trackern Aufgaben zu

### Unter welcher Prämisse wählt der Job-Tracker die Arbeitsknoten aus?

möchst hohe Datenlokalität, das heißt ein Arbeitsknoten hält die zu verarbeitenden Daten bereits

### Was ist Nachzügler-Ernenung bei einem MapReduce-Cluster?

meldet sich ein Arbeitsknoten über den Task-Tracker nicht beim Job-Tracker gilt der Task als
verloren und wird an einen anderen Knoten neu zugewiesen

### Wie verwenden die lokalen Ergebnisse eines Arbeitsknotens eines MapReduce-Clusters behandelt?

Ergebnisse sind nur temporär und werden daher nur auf der lokalen Festplatte des Arbeitsknotens
gespeichert, um nicht die Bandbreite des HDFS zu belasten. Die Daten werden erst im Hauptspeicher
gesammelt und vor dem Schreiben auf die Festplatte nach Schlüsseln Paritioniert (Shuffle-Phase)

### Wozu dient der Partitionierer bei einem MapReduce-Job?

ist mehr als ein Reduzier-Task nötig, müssen die Partitionierten Daten der Map-Tasks wieder verteilt
werden, das übernimmt der Partitionierer bzw. die Partitionierfunktion

### Wozu dient der Kombinierer bei einem MapReduce-Job?

während des Map-Tasks werden ggf. mehrfach identische Ausgaben erzeugt. Statt alle Ausgaben einzeln
zu speichern und erst im Reduce-Schritt zu reduzieren, kann jeder Map-Task im Vorfeld ergebnisse des
Map-Schritts kombinieren, um Festplattenplatz zu sparen und Arbeit aus dem Reduce-Schritt vorweg zu
nehmen

### Was sind die Anforderungen an eine Kombinierfunktion eines MapReduce-Jobs?

Eingaben und Ausgaben müssen der Struktur der Eingaben des Reduce-Jobs, also auch der Ausgabe des
Map-Jobs entsprechen

### Welche drei großen Einschränkungen wies die Version 1 von Hadoop auf?

- Skalierbarkeit: Nur ein Job-Tracker
- Spezialisierung: Nur MapReduce Workloads
- statische Aufgabenzuordnung: Ein Reduce-Knoten kann keine Map-Tasks übernehmen

### Welche Einschränkungen bezüglich Skalierbarkeit wies die Version 1 von Hadoop auf?

weil es nur einen Job-Tracker gab, der sowohl den Fortschritt Überwachen als auch Task verteilen
muss, kam er bei großen Clustern nicht schnell genug hinterher

### Welche Einschränkungen bezüglich Spezialisierung wies die Version 1 von Hadoop auf?

ein Hadoop-Cluster konnte nur MapReduce-Jobs ausführen, was aber für Graphenverarbeitung oder
iterative Aufgaben nicht geeignet ist

### Welche Einschränkungen bezüglich der Aufgabenverteilung wies die Version 1 von Hadoop auf?

ein Arbeiterknoten war entweder für Map-Tasks oder für Reduce-Tasks bestimmt, wenn gerade kein
Reduce-Task läuft, kann ein Reduce-Knoten keinen Map-Task übernehmen

### Welche Komponenten erweitern Hadoop v2 gegenüber v1?

- YARN: Resourcenmanagement (ausgelagert aus MapReduce v1)
- Spark:
- Spark SQL:
- MLib:
- Graphx:
- Stream:

### Wofür steht die Abkürzung YARN?

Yet Another Ressource Negotiator

### Aus welchen vier Komponenten besteht YARN?

- Container
- Ressourcenmanager (Ressource Manager)
- Anwendungsmaster (Application Master)
- Knotenmanager (Node Manager)

### Was ist ein Container von YARN?

- Grundlage der Ressourcenaufteilung
- Einheit von Zuweisungsressourcen

### Was sind die drei Kernkomponenten des Ressourcenmanagers von YARN?

- Anwendungsmanager (Application Manager)
- Scheduler
- Sicherheitskomponente

### Was ist die Aufgabe des Anwendungsmanager im Ressourcenmanager von YARN?

- Annahme von Anfragen und Aufträgen von Klienten und Annahme aller anwendungsbezogenen Anfragen der
  Klienten
- Validieren der Anwendungsspezifikationen und Bereitstellung der Ressourcen für die Ausführung des
  Anwendungsmasters (siehe unten mehr zum Anwendungsmaster)
- Neustart des Anwendungsmasters im Falle eines Fehlers
- Überwachung des Anwendungsfortschritts und Protokollierung der Laufzeitinformationen der
  Anwendungen

### Welche Scheduling-Algorithmen beinhaltet YARN?

- FIFO
- Kapazitäts-Scheduler
- fairer Scheduler

### Was zeichnet den FIFO-Scheduler von YARN aus?

Aufträge werden ihrem Eintreffen entsprechend der Reihe nach bearbeitet

### Was zeichnet den Kapazitäts-Scheduler von YARN aus?

Es werden mehrere Warteschlangen für ggf. unterschiedlich große Bruchteile der Kapazitäten des
Clusters verwaltet. Innerhalb einer jeden dieser Gruppe werden Aufträge nach dem FIFO Prinzip
abgearbeitet. Dadurch können große / lange Aufträge einer Gruppe nicht die Aufträge einer anderen
Gruppe blockieren

### Was zeichnet den fairen Scheduler von YARN aus?

alle verfügbaren Ressourcen werden auf die laufenden Anwendungen aufgeteilt

### Wozu dient die Sicherheitskomponenten des Ressourcenmanagers von YARN?

Verwalten von Zugriffen zwischen Anwendung und Container mittels Tokens

### Was ist der Application Master von YARN?

ein Application Master wird vom Ressourcenmanager für jede Art von eingereichten Jobs einmal
gestartet und verhandelt mit dem Ressourcenmanager die für eine Anwendung verwendeten Knoten. In
Zusammenarbeit mit den Knotenmanagern auf diesen Knoten wird der Fortschritt des Jobs verfolgt.

### Was ist der Kotenmanager von YARN?

ein Prozess, der auf jedem Worker-Node des Clusters läuft und auf diesem den Lebenszyklus von
Containern verwaltet. Der Knotenmanager sendet Informationen über den aktuellen Zustand des Knoten
an den Ressourcenmanager

### Was ist *Spark*?

ein Programmiermodell, das effizientes, mehrfaches wiederverwenden von Daten in parallelen
Berechnungen zu ermöglichen. Es ist in die Hadoop v2 Architektur integrierbar und nutzt dabei YARN
zur Ressourcenverwaltung

### Welche Cluster Manager unterstützt Spark?

- Standalone (kommt mit Spark)
- Apache Mesos (deprecated)
- Hadoop YARN
- Kubernetes

### Welche 2 Arten von Prozessen sind an einer Spark-Anwendung beteiligt?

- Treiberprozess (Driver)
- Ausführungsprozesse (Executor)

### Was ist der *Treiberprozess* in Spark?

Der Prozess der einer definierte `main` Funktion ausführt

### Was sind die Aufgaben des Treiberprozesses in Spark?

- Ausführen der `main` Funktion der Anwendung
- Informationen über die Anwendung verwalten
- Reagieren auf Benutzerprogramm / Benutzereingaben
- Analysieren, Verteilen, Planen der Arbeit der Ausführungsprozesse

### Welche 3 Clustermodi hat Spark zur Verweilung der Prozesse?

- Cluster-Modus
- Client-Modus
- lokaler Modus

### Was zeichnet den Cluster-Modus von Spark aus?

die Anwendung wird dem Clustermanager (z.B. YARN) übergeben, der dann der Treiberprozess und die
Ausführungsprozesse auf Clusterknoten startet.

### Was zeichnet den Client-Modus von Spark aus?

der Treiberprozess verbleibt auf dem Client-Rechner, nur die Ausführungsprozesse werden auf die
Knoten des Clusters verteilt

### Was zeichnet den lokalen Modus von Spark aus?

Parallelisierung geschieht durch Thread auf einer lokalen Maschine, gut geeignet als Trainigs- und
Entwicklungsumgebung

### Welche Programmiersprachen unterstützt die Spark-API?

- Scala (Standardsprache, weil Spark in Scala geschrieben)
- Java
- Python
- SQL
- R

### Wofür steht die Abkürzung RDD (Spark)?

resilient distributed dataset

### Wozu dienen Resilient Distributed Datasets in Spark?

Abstraktion eines auf mehrere Knoten verteilten, read-only Datensatzes

### Welche 5 Eigenschaften kennzeichnen ein Resilient Distributed Dataset?

- Funktion zur Berechnung der Aufteilung und der Daten der Partitionen
- Liste von Abhängigkeiten zu anderen RDDs
- Partitionierer für Schlüssel-Wert-RDDs (optional)
- Liste der bevorzugten Speicherorte (optional)
- Liste mit Partitionen

### Was bedeutet es, dass ein RDD "resilient" ist?

wegen der gespeicherten Historie der vorgenommenen Transformationen kann ein RDD jederzeit auf Basis
der Ausgangsdaten wiederherstellt werde, falls zum Beispiel ein Knoten ausfällt

### Welche 2 Arten von Operation sind auf RDDs definiert?

- Transformations (triggern keine RDD Berechnung, sondern erweiter die *lineage*)
- Actions (triggern die Berechnung aller Transformations)
